{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests (RF)\n",
    "### Definition\n",
    "- Base estimator: Decision Tree\n",
    "- Each estimator is trained on a different bootstrap sample having the same size as the training set. \n",
    "- RF introduces further randomization in the training of individual trees\n",
    "\n",
    "![title](https://drive.google.com/uc?export=view&id=1r5FGL17FR5IHOm8RAArXXJWl2NWGIQHF)\n",
    "\n",
    "### Steps\n",
    "1. Build a bootstrapped dataset, with the same shape as the original dataset\n",
    "    - Take random observations (rows) from the original dataset\n",
    "2. Create a decision tree using the bootstrapped dataset, but only use a random subset of variables (columns) at each step.\n",
    "3. Go to step 1 and repeat\n",
    "\n",
    "### Advantages and limitations\n",
    "**Advantages**:\n",
    "- Random Forests combine the simplicity of decision trees with flexibility resulting in a vast improvement in accuracy.\n",
    "- The variety is what makes random forests more effective than individual decision trees.\n",
    "- ***BAGGING tends to decrease variance, not bias. Thus, it tries to resolve the issue of overfitting the training data.*** \n",
    "\n",
    "**Feature Importance**:\n",
    "- Tree-based methods: enable measuring the importance of each feature in prediction. \n",
    "    - how much the tree nodes use a particular feature to reduce impurity\n",
    "\n",
    "### Clustering\n",
    "**Proximity Matrix**:\n",
    "- We know that two samples (rows) are similar if both end up in the same leaf node. \n",
    "- A Matrix can be build, with 0s and 1s, when the above is met. \n",
    "- This is repeated for each decision tree in the random forest, and values are aggregated in the matrix. \n",
    "- Then we divide each proximity value by the total number of trees.\n",
    "- The closer the values to 1, the less distance there is between the samples!! BAM\n",
    "    - We can build a heatmap or an MDS to represent the distances to each other! \n",
    "    - It doesn't matter if it numeric or categorical.\n",
    "\n",
    "![title](https://drive.google.com/uc?export=view&id=1gJ-79NoPUkx0BAUtti_QDMbUdJGZJdBE)\n",
    "\n",
    "### Missing data\n",
    "**Types**:\n",
    "1. On the training data set\n",
    "    - The general idea for dealing with missing data in this context is to make an initial guess that could be bad, then gradually refine the guess until it is (hopefully) a good guess. \n",
    "        - For example, we could group by the target value (heart disease - 0, 1) and take the most repeated value or the average to fill the nans.\n",
    "2. On the test data set\n",
    "    - We don't know the target value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 3.7603781331419897\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE \n",
    "\n",
    "# Import data\n",
    "file1 = 'https://raw.githubusercontent.com/prince381/car_mpg_predict/master/cars1.csv'\n",
    "file2 = 'https://raw.githubusercontent.com/prince381/car_mpg_predict/master/cars2.csv'\n",
    "cars1 = pd.read_csv(file1).dropna(how='all', axis=1)\n",
    "cars2 = pd.read_csv(file2)  \n",
    "df = pd.concat([cars1, cars2], ignore_index=True, sort=False)\n",
    "\n",
    "# Split data\n",
    "seed = 1\n",
    "X = df[['displacement']].to_numpy().reshape(-1, 1)\n",
    "y = df['mpg'].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "\n",
    "# Instantiate and train model\n",
    "rf = RandomForestRegressor(n_estimators=400, min_samples_leaf=0.12, random_state=seed)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse_test = MSE(y_test, y_pred) ** (1/2)\n",
    "print(f\"Test set RMSE: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aphrodite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
